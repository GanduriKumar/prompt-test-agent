# ============================================================================
# Multi-Provider LLM Configuration
# ============================================================================
# This file shows all available configuration options for different LLM providers.
# Copy this file to .env and configure for your chosen provider.

# ----------------------------------------------------------------------------
# PROVIDER SELECTION
# ----------------------------------------------------------------------------
# Choose your LLM provider: 'ollama', 'openai', 'anthropic', 'google', 'azure'
LLM_PROVIDER=ollama

# ----------------------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------------------
# Specify models for different tasks (defaults vary by provider)

# Main model for text generation (test case generation)
# LLM_MODEL=llama3.2
LLM_MODEL=gpt-5.1


# Model for vision tasks (screenshot analysis)
# If not set, uses LLM_MODEL
LLM_VISION_MODEL=llama3.2-vision

# Model for code generation (Playwright automation)
# If not set, uses LLM_MODEL
LLM_CODING_MODEL=deepseek-coder:6.7b

# ============================================================================
# OLLAMA CONFIGURATION (Local LLM)
# ============================================================================
# For running models locally with Ollama

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Legacy environment variables (backward compatibility)
# These are used if LLM_* variables are not set
OLLAMA_MODEL=llama3.2
VISION_MODEL=llama3.2-vision
CODING_MODEL=deepseek-coder:6.7b

# Popular Ollama models:
#   Text: llama3.2, llama3.1, mistral, mixtral, gemma2
#   Vision: llama3.2-vision, llava, bakllava
#   Code: deepseek-coder:6.7b, codellama:13b, starcoder2

# ============================================================================
# OPENAI CONFIGURATION (GPT-4, GPT-3.5)
# ============================================================================
# For using OpenAI's hosted models

# OpenAI API key (required)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenAI base URL (optional, defaults to https://api.openai.com/v1)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Recommended models:
#   LLM_MODEL=gpt-4-turbo-preview  (best quality)
#   LLM_MODEL=gpt-4-1106-preview   (good balance)
#   LLM_MODEL=gpt-3.5-turbo-1106   (fast, cheaper)
#   LLM_VISION_MODEL=gpt-4-vision-preview  (for screenshots)
#   LLM_CODING_MODEL=gpt-4-turbo-preview   (for code gen)

# ============================================================================
# ANTHROPIC CONFIGURATION (Claude)
# ============================================================================
# For using Anthropic's Claude models

# Anthropic API key (required)
# Get from: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Recommended models:
#   LLM_MODEL=claude-3-opus-20240229    (highest quality)
#   LLM_MODEL=claude-3-sonnet-20240229  (balanced)
#   LLM_MODEL=claude-3-haiku-20240307   (fastest)
#   LLM_VISION_MODEL=claude-3-opus-20240229  (supports vision)

# ============================================================================
# GOOGLE CONFIGURATION (Gemini)
# ============================================================================
# For using Google's Gemini models

# Google API key (required)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Recommended models:
#   LLM_MODEL=gemini-pro              (text generation)
#   LLM_VISION_MODEL=gemini-pro-vision (image understanding)

# ============================================================================
# AZURE OPENAI CONFIGURATION
# ============================================================================
# For using OpenAI models hosted on Azure

# Azure OpenAI API key (required)
AZURE_OPENAI_API_KEY=your-azure-api-key-here

# Azure OpenAI endpoint (required)
# Format: https://YOUR-RESOURCE-NAME.openai.azure.com
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com

# Azure OpenAI API version
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Azure deployment name (the name you gave when deploying the model)
AZURE_OPENAI_DEPLOYMENT=gpt-4

# For multiple models, you can use deployment names directly:
#   LLM_MODEL=your-gpt4-deployment-name
#   LLM_VISION_MODEL=your-vision-deployment-name
#   LLM_CODING_MODEL=your-coding-deployment-name

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# Example 1: Ollama (Local, Free)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# LLM_VISION_MODEL=llama3.2-vision
# LLM_CODING_MODEL=deepseek-coder:6.7b
# OLLAMA_BASE_URL=http://localhost:11434

# Example 2: OpenAI (Hosted, Best Quality)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4-turbo-preview
# LLM_VISION_MODEL=gpt-4-vision-preview
# LLM_CODING_MODEL=gpt-4-turbo-preview
# OPENAI_API_KEY=sk-...

# Example 3: Anthropic Claude (Hosted, High Quality)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-opus-20240229
# LLM_VISION_MODEL=claude-3-opus-20240229
# LLM_CODING_MODEL=claude-3-opus-20240229
# ANTHROPIC_API_KEY=sk-ant-...

# Example 4: Google Gemini (Hosted, Free Tier Available)
# LLM_PROVIDER=google
# LLM_MODEL=gemini-pro
# LLM_VISION_MODEL=gemini-pro-vision
# GOOGLE_API_KEY=...

# Example 5: Azure OpenAI (Enterprise)
# LLM_PROVIDER=azure
# LLM_MODEL=gpt-4
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=gpt-4

# ============================================================================
# COST CONSIDERATIONS
# ============================================================================
# Approximate costs per 1M tokens (as of 2024):
#
# Ollama:      $0 (local, uses your hardware)
# GPT-4:       $30 input, $60 output
# GPT-3.5:     $0.50 input, $1.50 output
# Claude 3:    $15 input, $75 output (Opus)
# Claude 3:    $3 input, $15 output (Sonnet)
# Gemini Pro:  $0.50 input, $1.50 output (free tier available)
#
# Typical test generation uses ~5,000-10,000 tokens per URL
# Estimated cost per URL: $0.05-$0.50 depending on provider/model

# ============================================================================
# PERFORMANCE COMPARISON
# ============================================================================
# Typical test generation times (single URL):
#
# Ollama (CPU):           30-60 seconds
# Ollama (GPU):           10-20 seconds
# OpenAI GPT-4:           15-30 seconds
# OpenAI GPT-3.5:         5-10 seconds
# Anthropic Claude:       10-25 seconds
# Google Gemini:          8-15 seconds
# Azure OpenAI:           15-30 seconds
#
# Speed depends on: model size, network latency, API rate limits

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# If using Ollama and getting connection errors:
# 1. Make sure Ollama is running: ollama serve
# 2. Verify models are installed: ollama list
# 3. Check OLLAMA_BASE_URL is correct

# If using cloud providers and getting auth errors:
# 1. Verify API key is correct and active
# 2. Check you have sufficient credits/quota
# 3. Ensure API key has required permissions

# If getting rate limit errors:
# 1. Add delays between requests
# 2. Use batch processing
# 3. Consider upgrading your API plan
